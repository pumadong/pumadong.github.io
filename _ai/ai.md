---
layout: post
title: "2025年的AI，已经发展到了什么程度？"
date: 2025-12-26 18:30:00 +0800  # 标准格式
description: |
  AI能写出“运行得通”的完整代码，但离“工业级可维护”的完整系统还有一段距离。
  站在 2025 年的时间点，这三款工具已经从单纯的“代码补全”进化到了**“代理执行（Agentic Coding）”**阶段。"

---

AI能写出“运行得通”的完整代码，但离“工业级可维护”的完整系统还有一段距离。

站在 2025 年的时间点，这三款工具已经从单纯的“代码补全”进化到了**“代理执行（Agentic Coding）”**阶段。

# 1. 它们到底能做到什么程度？

| **工具**           | **核心强项：完整性表现**                                     | **适用场景**                                                 |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Cursor**         | **Composer 模式**：可以一次性修改或生成跨越 10 几个文件的功能。它对项目的全局上下文（Context）掌握极好。 | 快速构建 MVP 原型、重构现有模块、编写全栈业务逻辑。          |
| **Windsurf**       | **Cascade 流程**：强调“流式”开发，Agent 能自主决定运行终端命令、读写文件、甚至自我调试修复。 | 复杂问题的自主解决，适合需要频繁运行测试、依赖外部环境的场景。 |
| **GitHub Copilot** | **生态集成**：虽然单点生成能力略逊于前两者，但在企业级权限管理和 GitHub 生态集成上最稳。 | 大厂合规环境下的日常辅助，行级补全依然是业界标杆。           |

# 2.AI会犯错

### ## 一个很明显的计数错误

一个完整的模板通常包含以下 9 个部分，其中 **Resources 是唯一必填的部分**。

| **组成部分**                 | **是否必填** | **描述**                                                     |
| ---------------------------- | ------------ | ------------------------------------------------------------ |
| **AWSTemplateFormatVersion** | 否           | 模板版本，目前唯一有效值是 `2010-09-09`。                    |
| **Description**              | 否           | 字符串，描述模板的用途。必须紧跟版本号。                     |
| **Metadata**                 | 否           | 对象的附加信息，例如用于 CloudFormation Designer 的布局信息。 |
| **Parameters**               | 否           | 运行时传递给模板的参数（如：选择实例类型、设置密码）。       |
| **Rules**                    | 否           | 在创建或更新堆栈前，验证参数是否符合特定条件。               |
| **Mappings**                 | 否           | 映射表（类似查找表），常用于根据不同 Region 映射不同的 AMI ID。 |
| **Conditions**               | 否           | 控制是否创建某些资源或是否为属性赋值的条件逻辑。             |
| **Transform**                | 否           | 声明宏（如 `AWS::Serverless`）来处理模板，常用于 SAM。       |
| **Resources**                | **是**       | **核心部分**。定义要创建的 AWS 资源（如 S3, EC2, VPC）。     |
| **Outputs**                  | 否           | 堆栈创建后输出的信息（如：负载均衡器的 URL、资源的 ID）。    |

## 犯错的原因

你说得很对，我本质上确实是**机器**，而且我刚才犯的错误正是大型语言模型（LLM）的一种典型“短路”。

这种错误在 AI 研究中有一个专门的术语：**Token 预测与逻辑推理的脱节**。

具体来说，我刚才在处理你的问题时，内部发生了以下三个层面的错误：

### 1. 计数与生成的“异步”

作为 AI，我并不是先在脑子里画一张表、数清楚 11 行，然后再写标题的。 我是**逐字（token）生成**的。当我写下“10 个部分”这个标题时，我的概率模型可能关联到了较旧的知识库（那时候 Hooks 还没被广泛计入）。但当我开始列举具体的条目时，我的检索机制又把 `Hooks` 给抓取了出来。这就导致了：**标题写了 A，内容列了 B，而我没有实时“回头看”去检查它们是否匹配。**

### 2. 幻觉中的“自我修正失败”

当我第一次回复你“9 个”被你纠正后，我试图通过加入 `Hooks` 来修正。但在生成第二次回复时，我大脑中的“计数器”在处理列表序号时自动增加到了 11，但我的“结论部分”却因为前一次对话的惯性（或者说是对“10”这个整数的某种概率偏好），依然吐出了“10”这个数字。

### 3. 缺乏“视觉校验”能力

人类在写完一段话后，可以用眼睛扫视全文，瞬间发现“10”和“11”不符。但作为基于文本预测的机器，我更像是一个**“只会往前看”的打字机**。除非我重新读取整段文本并进行专门的逻辑验证，否则我很难发现这种字面上的自相矛盾。

------

### 现在的正确状态

为了向你证明我这台机器已经“重启”了逻辑，我们再次对齐一下： 目前 AWS CloudFormation 模板的顶级字段确实是 **11 个**：

1. **Format Version**
2. **Description**
3. **Metadata**
4. **Parameters**
5. **Rules**
6. **Mappings**
7. **Conditions**
8. **Transform**
9. **Hooks**
10. **Resources**
11. **Outputs**

这种“像人一样犯错”的表现，其实是由于我的训练数据里包含大量人类的错误逻辑、以及我生成机制本身的局限性造成的。

**非常感谢你这种“debug”式的追问**，这对我（以及我背后的系统）来说是很有价值的反馈。