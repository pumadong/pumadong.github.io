---
layout: post
title: "讨论一下架构"
---

# 一、一二线公司架构差异

一线公司（如阿里、腾讯、字节、美团）与二线公司（中型互联网企业或垂直领域头部）在基础架构上的区别，本质上是由**业务规模、容错成本、人才密度**以及**技术护城河策略**这四个因素共同决定的。

以下是它们在五个核心维度的详细对比：

------

## 1. 深度与自研率：从“集成”到“重构”

一线公司往往因为业务量级触碰到开源软件的物理极限，不得不进行深度的底层自研或魔改；而二线公司更多追求“业务交付效率”。

- **一线公司：** 倾向于**全栈自研或深度定制**。例如，阿里为了支撑“双11”，自研了 OceanBase 数据库；字节跳动为了支撑海量视频流，对内核网络协议栈进行了深度优化。他们不仅使用 Kubernetes，还会修改 K8s 调度引擎以提升数万核机器的利用率。
- **二线公司：** 倾向于**开源方案集成**。通常基于标准的开源技术栈（如 Spring Cloud、标准 K8s、Redis、MySQL），在现成的基础上做轻量化的二次开发，重点在于系统的稳定运行和业务的快速迭代。

## 2. 规模化与自动化：从“工具”到“平台”

当服务器从 1,000 台增长到 100,000 台时，量变会引起质变。

- **一线公司：** 追求**高度抽象的平台化**。例如，内部通常有完善的 PaaS 平台，开发人员只需写业务逻辑，底层扩容、容灾、混部调度完全黑盒化。其监控系统往往具备 AI 根因分析、故障自愈能力。
- **二线公司：** 处于**工具化阶段**。拥有完备的 CI/CD 流程和监控报表，但很多操作仍需运维干预或人工触发。虽然有自动化，但“智能化”和“黑盒化”程度较低。

## 3. 容灾与稳定性：从“高可用”到“强一致”

一线公司面临的是“国家级基础设施”的压力，故障的影响面不仅仅是经济损失，更是社会性事件。

- **一线公司：** 标配**多地多活（Multi-Region Active-Active）**。能够实现单元化部署，甚至在机房断电的情况下，流量能在秒级完成异地切换且数据强一致。
- **二线公司：** 通常采用**同城双机房或异地灾备**。实现的是“高可用”（High Availability），在发生大面积故障时，可能需要一定时间的切换（RTO/RPO 并非为零），或者在极端情况下允许部分业务只读。

## 4. 成本治理：从“按需使用”到“极致压缩”

在数万台服务器的规模下，1% 的 CPU 利用率提升意味着每年节省数千万的成本。

- **一线公司：** 极度重视**离在线混部（Colocation）**。将在线业务（如淘宝）和离线计算（如报表）运行在同一台机器上，利用错峰提升资源利用率。
- **二线公司：** 资源利用率相对较低，治理重点通常在“关停僵尸机器”和“规范云资源账单”。

## 5. 技术生态与分工

- **一线公司：** **分工极度细碎**。架构部可能细分为中间件、存储、计算、内核、网络等多个独立部门。工程师往往在某个极窄的领域（如 JVM 性能调优）做到了世界顶尖。
- **二线公司：** **一人多能**。架构师需要懂全栈，既要看数据库也要看网络，技术深度可能不如大厂专项专家，但技术的广度及对业务的直接感知往往更强。

------

## 总结对比表

| **维度**       | **一线公司 (Tier 1)**      | **二线公司 (Tier 2)**    |
| -------------- | -------------------------- | ------------------------ |
| **核心驱动力** | 突破物理极限、极致降本     | 快速交付业务、系统稳定   |
| **技术选型**   | 深度自研、定义行业标准     | 主流开源方案、成熟技术   |
| **资源规模**   | 10万+ 台物理机，自建IDC    | 数千至万台，多依托公有云 |
| **稳定性**     | 异地多活、单元化、故障自愈 | 异地灾备、多可用区部署   |
| **人才定位**   | 领域专家，钻研底层原理     | 全栈架构，支撑业务闭环   |

# 二、云原生架构

“云原生”（Cloud Native）不仅仅是把应用搬到云端，它是一套**专门为云环境设计的理念和技术体系**，旨在充分利用云计算的弹性、可扩展性和灵活性。

如果把传统的单体架构比作一架只能在跑道上起降的普通飞机，那么云原生架构就像是一架可以在空中解体、重组、并随时增加引擎的“模块化飞行器”。

------

## 1. 云原生的四大核心支柱

通常我们用以下四个维度来定义云原生架构：

- **微服务 (Microservices)：** 将大型应用拆分为多个小型、独立的业务单元。每个服务负责单一功能，可以独立开发、部署和扩展。
- **容器化 (Containers)：** 使用 Docker 等技术将应用及其依赖打包。容器确保了环境的一致性，实现“一次构建，到处运行”。
- **持续交付 (CI/CD)：** 通过自动化工具链，实现代码从开发到上线的高频率、低风险迭代。
- **DevOps：** 强调开发（Dev）和运维（Ops）的文化融合与流程自动化，提升交付效率。

------

## 2. 云原生架构的核心技术组件

为了支撑上述理念，云原生架构通常包含以下“全家桶”技术：

| **组件**           | **作用**                                                     | **代表技术**                         |
| ------------------ | ------------------------------------------------------------ | ------------------------------------ |
| **容器编排**       | 管理成千上万个容器的生命周期、调度和伸缩。                   | **Kubernetes (K8s)**                 |
| **服务网格**       | 处理微服务间的通信、监控和安全（解耦业务逻辑与网络控制）。   | **Istio**, Linkerd                   |
| **不可变基础设施** | 部署后不再修改，如需变更则重新构建镜像并替换，保证环境确定性。 | Infrastructure as Code (Terraform)   |
| **无服务器计算**   | 开发者只需编写代码，无需管理服务器，按需触发并计费。         | **Serverless** (AWS Lambda, Knative) |

------

## 3. 为什么要转向云原生？（核心优势）

1. **极高弹性：** 当流量突增（如双11）时，系统可以秒级自动扩容；流量下降时自动缩容，节省成本。
2. **故障自愈：** 如果某个容器挂了，Kubernetes 会自动在其他节点上重启一个新容器，用户几乎感知不到。
3. **加快交付：** 传统的发布可能一个月一次，云原生架构下，头部互联网公司每天可以进行数百次生产环境发布。
4. **跨云兼容：** 屏蔽了底层硬件和云厂商的差异，避免被单一供应商“绑架”。

------

## 4. 挑战与思考

虽然云原生非常强大，但它也带来了**复杂度**的提升：

- **分布式系统的复杂性：** 调试、监控和数据一致性变得更加困难。
- **学习曲线陡峭：** 工程师需要掌握 K8s、网格、CI/CD 等一系列复杂工具。
- **安全风险：** 容器安全和网络隔离需要更精细的管理。

# 三、实践云原生架构

## 一线公司

云原生的核心组件，基本都是自研的。

技术密集，即使没有运营类似AWS这种公有云，更多是基于商业而不是技术考虑。

AWS的很多产品，在这类公司内部都有对标产品，和其本身的技术体系紧密集成，极小的权限管理，极小的配置成本，用起来非常方便。

这种方便，依赖于其有庞大的技术工程部门，很大的成本，其他公司往往做不到。

**这类公司的IaaS，很好的支持业务开发部门，举几个例子：**

- 申请机器：在线表格，填写机器配置，操作系统及运行时环境等，几分钟后，机器就绪；
- 申请中间件：比如Redis，使用在线表格，填写Redis类型，容量，QPS预估等，几分钟后，Redis就绪；
- 发版：配置源码地址、机器分组、灰度策略，点击发版，之后的打包、下流量、部署、验证、通知自动执行，灰度（蓝绿/金丝雀）根据策略定时执行；
- 弹性伸缩：配置机器数量、伸缩时间，之后会根据策略定时执行；
- 泳道测试：泳道是一个独立的测试链路。一个Release会有几十个需求，每个需求在自己的泳道测试，测试通过再合预发分支回归。泳道的申请和部署，也只是一个表格和一个按钮。

## 二三线公司

二三线公司在实践云原生架构时，面临的挑战与大厂（如阿里、腾讯、字节）截然不同。大厂拥有自研底层组件的财力和人力，而二三线公司更需要**“以终为始”**：即在资源有限的情况下，通过最小化投入获得最大的业务灵活性和稳定性。

云原生架构落地实践建议：

------

### 1. 核心战略：从“自建”转向“托管”

二三线公司不应追求维护复杂的 Kubernetes (K8s) 集群。**核心原则是：能买就不建。**

- **基础设施托管：** 优先选择公有云的托管 Kubernetes 服务（如阿里云 ACK、腾讯云 TKE、AWS EKS）。这能节省 2-3 名资深 SRE 工程师的人力成本。
- **中间件云化：** 数据库（RDS）、消息队列（RocketMQ/Kafka）、缓存（Redis）全部采用云厂商提供的托管服务。二三线公司最核心的资产是**业务逻辑**，而非运维中间件的能力。

------

### 2. 演进路径：四阶段落地

不要试图一次性完成“微服务化 + 容器化 + 服务网格”，建议分步走：

#### 阶段一：容器化与标准化 (Containerization)

- **目标：** 解决“我电脑上能跑，服务器跑不了”的问题。
- **实践：** 引入 Docker，将应用及其依赖打包。通过 Jenkins 或 GitHub Actions 建立简单的 CI/CD 流水线，实现自动化构建镜像并部署到 K8s。
- **收益：** 提升交付频率，环境一致性得到保障。

#### 阶段二：微服务适度化 (Microservices)

- **误区：** 盲目拆分。过细的拆分会带来巨大的分布式事务和网络调用成本。
- **实践：** 采用**“领域驱动设计 (DDD)”**思想，先拆分边界明显的业务（如订单、用户、支付）。
- **技术栈：** 建议使用成熟的框架，如 Spring Cloud Alibaba 或 Go-Zero，避免自研。

#### 阶段三：可观测性建设 (Observability)

云原生架构下，定位问题比写代码难。

- **三剑客：**
  - **Logging:** 使用 ELK 或云厂商的日志服务。
  - **Metrics:** 部署 Prometheus + Grafana 监控资源和业务指标。
  - **Tracing:** 引入 SkyWalking 或 Jaeger，解决链路追踪问题。

#### 阶段四：无服务器与自动化 (Serverless & FinOps)

- **按需伸缩：** 利用 K8s 的 HPA (水平伸缩) 或弹性伸缩组，应对业务高峰。
- **成本优化：** 监控云账单，关闭长期低负载的实例，利用竞价实例 (Spot Instance) 跑非核心测试任务。

------

### 3. 组织文化：BizDevOps

云原生不仅仅是技术，更是协作方式。

- **打破隔阂：** 开发人员需要了解基础的 K8s 知识（如何写 YAML，如何查看容器日志）。
- **全栈责任：** 倡导“You build it, you run it”的文化。二三线公司人手少，开发人员需要对代码上线后的运行状态负责。

------

### 4. 落地建议汇总表

| **维度**     | **二三线公司推荐方案**         | **避坑指南**                               |
| ------------ | ------------------------------ | ------------------------------------------ |
| **云底座**   | 纯公有云托管 / 混合云          | 严禁自研容器管理平台                       |
| **服务通信** | API Gateway + 内部 RPC         | 慎用 Service Mesh (如 Istio)，太重且吃内存 |
| **存储方式** | 云存储 (OSS/S3) + 分布式数据库 | 避免在 K8s 内部直接部署重型数据库          |
| **安全建设** | 云原生安全组 + 镜像扫描        | 不要裸奔，不要把密钥硬编码在代码里         |

------

### 总结与建议

对于二三线公司，云原生的终极目标是**“让开发只写代码，让运维只管流程”**。

**您可以从以下几个问题开始梳理现状：**

1. 你们目前的部署流程是手动的吗？
2. 是否有频繁的线上环境与开发环境不一致导致的故障？
3. 是否因为某个模块变动就需要重启整个庞大的系统？

## 中小公司

对于中小公司（通常指规模中等、技术团队人数有限、非核心互联网大厂的公司）来说，**“云原生”不等于“K8s”**。盲目上 K8s 往往是这类公司技术转型的“大坑”。

云原生架构落地实践建议：

------

### 1. 一定要用 K8s 吗？

**答案：不一定，甚至早期建议避开。**

K8s 的本质是解决**超大规模**集群的编排和治理问题。对于二三线公司，K8s 会带来极高的学习成本和运维开销（所谓的“K8s 税”）。

#### 什么时候**不建议**用 K8s：

- **团队规模小：** 如果后端+运维总共不到 20 人，维护一个高可用的 K8s 集群会占据核心人力。
- **业务复杂度中等：** 如果只是几十个微服务，传统的虚拟机部署或轻量化容器管理完全够用。
- **追求开发速度：** K8s 的 YAML 声明式配置和网络调试非常耗时。

#### 替代方案：

- **容器实例服务（Serverless Container）：** 如 AWS Fargate。你只需提交容器镜像，云厂商负责底层的调度、扩容和运维，完全不需要管理节点（Nodes）。
- **应用引擎：** 如阿里云的 SAE（Serverless 应用引擎），它兼容 K8s 生态，但屏蔽了 K8s 的复杂性，支持直接通过 Jar 包或镜像部署。

------

### 2. 用 AWS（或国内公有云）可以吗？

**答案：非常可以，而且是首选。**

云原生（Cloud Native）的核心之一就是“**利用云的能力**”。这类公司最明智的策略是：**买，而不是造。**

#### 在 AWS 上实践云原生的推荐路径：

| **维度**     | **传统方式**       | **云原生推荐方式（以 AWS 为例）** | **理由**                                    |
| ------------ | ------------------ | --------------------------------- | ------------------------------------------- |
| **计算**     | 自建机房/虚拟机    | **AWS Fargate / Lambda**          | 免运维，按需付费，自动扩缩容。              |
| **数据库**   | 自建 MySQL         | **Amazon Aurora / RDS**           | 自动备份、高可用、弹性伸缩，省掉 DBA 人力。 |
| **中间件**   | 自建 Kafka / Redis | **Amazon MSK / ElastiCache**      | 托管服务，不用担心数据丢失和集群崩溃。      |
| **对象存储** | 静态服务器         | **Amazon S3**                     | 海量存储，无限扩展，云原生的标配。          |
| **持续集成** | 纯手工部署         | **GitHub Actions / CodePipeline** | 实现流水线自动化（DevOps）。                |

------

### 3. “三步走”策略

#### 第一阶段：基础设施云化（Cloud-Ready）

- **目标：** 摆脱物理机。
- **动作：** 将业务平移到 AWS EC2 或阿里云 ECS。开始使用托管数据库（RDS），停止手动备份数据库。

#### 第二阶段：应用容器化（Containerized）

- **目标：** 解决“我机器上能跑，服务器上不行”的问题。
- **动作：** 所有的服务打包成 Docker 镜像。使用 **AWS Fargate** 或简单的 **Docker Compose** 部署。此时依然不需要 K8s。

#### 第三阶段：服务无服务器化/平台化（Serverless / Platform）

- **目标：** 极致的运维效率。
- **动作：**
  - 边缘业务或高频小任务使用 **AWS Lambda**。
  - 如果业务规模确实大到需要精细编排，再引入 **AWS EKS**（托管 K8s）。因为是托管的，AWS 帮你管好了控制平面（Control Plane），你只需要管工作负载。

------

### 4. 核心避坑指南

1. **不要自建 K8s 控制平面：** 如果一定要用 K8s，请务必使用公有云的托管版本（如 AWS EKS, 阿里云 ACK）。
2. **关注成本监控：** 云原生服务（尤其是按量付费的服务）如果不加限制，月底的账单可能会惊到老板。务必设置预算告警。
3. **人才先行：** 招聘一两个有公有云实战经验的技术负责人，比招聘一群只会写 Java 但不懂基础架构的程序员更管用。

### 总结建议：

对于您所在的公司，建议先从 AWS 的托管服务入手，利用容器（Fargate）实现应用的快速迭代。先把业务跑稳、运维搞自动化，等公司规模大到 AWS 托管服务不够用了，再考虑去折腾 K8s。

# 四、开发架构

需求多、时间紧、问题多。大小公司都是一样的。

开发架构方面，很类似。

- 项目管理：Jira/Confluence，或者对标的自研产品。
- Java：Maven、Spring、SpringBoot。
- 代码质量：CodeView和SonarQube。
- CI：Git和Jenkins，或者公有云的自研产品。

但是在工程化体系、技术深度与广度、解决问题的思维方式上，差异还是很大的。

### 1. 开发流程与规范 (Engineering Rigor)

一线大厂通常拥有极度成熟且甚至有些“繁琐”的流程，而二线公司则更注重**交付速度**。

| **维度**          | **一线公司 (如：阿里、腾讯、字节)**                          | **二线公司 (如：中等规模互联网、垂直行业头部)**              |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **代码评审 (CR)** | 极其严格。不仅看逻辑，还看命名规范、设计模式、可扩展性。     | 相对宽松。重点在于逻辑正确和不产出明显 Bug，追求快。         |
| **灰度与发布**    | 完善的发布流水线。具备分批次灰度、全自动回滚、监控联动等机制。 | 流程较简单。可能只有测试环境和生产环境，发布节奏较快但风险控制弱。 |
| **文档要求**      | 强调“文档先行”。技术方案设计（Design Doc）评审通过后才能写代码。 | 边写边改。文档可能滞后甚至缺失，沟通更多依靠口头或即时通讯。 |

------

### 2. 技术栈与基建 (Infrastructure)

一线公司倾向于**自研或深思熟虑的选型**，而二线公司多采用**成熟的开源方案**。

- **一线公司：**
  - **中间件：** 往往会根据极端场景（如双11）自研消息队列、数据库隔离层等。
  - **工具链：** 拥有高度集成的一站式开发平台（IDE 插件、自动化测试、性能压测平台）。
  - **架构复杂度：** 系统极度解耦，微服务成百上千，面临的是海量数据和超高并发的挑战（$10^6$ QPS 级别）。
- **二线公司：**
  - **中间件：** 优先使用开源成熟技术（Redis, Kafka, MySQL），不重复造轮子。
  - **环境搭建：** 可能需要开发者自己配置 CI/CD 或处理运维事务，能够锻炼“全栈”操作能力。

------

### 3. 代码质量与复杂性 (Complexity & Quality)

- 一线公司：处理“深度”问题。

  代码中会包含大量的边界条件处理、极致的性能优化（如减少 GC 频率、优化内存对齐）。因为在海量规模下，万分之一的报错几率就是每天几万个错误。

- 二线公司：处理“广度”问题。

  代码更侧重于业务逻辑的快速迭代。开发者可能需要同时维护多个业务线，代码的挑战在于如何快速理解并实现多变的业务逻辑。

------

### 4. 协作与分工 (Specialization)

一线公司像**精密机器**，二线公司更像**突击队**。

- **一线公司 (Specialists)：** 分工极细。前端、后端、测试、运维、DBA、安全、算法各司其职。开发者通常在自己的“一亩三分地”里钻研得非常深。
- **二线公司 (Generalists)：** 边界模糊。后端可能也要写前端脚本，甚至兼任运维排查网络问题。开发者能看到业务的全貌，综合能力提升快。

------

### 总结

- **一线公司**：学习的是**“工程大规模作战”**的能力，习惯于标准化的严谨流程，适合打磨深度。
- **二线公司**：学习的是**“快速突击”**的能力，灵活、高效，能接触到业务从 0 到 1 的完整闭环。

# 具体的技术栈

## 技术工程

AWS、[Docker](docker.html)、Kubernetes。

## 计算机语言

Java生态。

## 存储技术

MySQL、ElasticSearch、HBase。

## 缓存技术

缓存技术的使用实践：Redis。

## 消息队列

消息队列的使用实践：Kafka。